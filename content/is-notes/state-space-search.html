<!DOCTYPE html>
<html>
<head>
<link rel="Stylesheet" type="text/css" href="style.css">
<script type="text/javascript" async src="https://cdn.jsdelivr.net/gh/mathjax/MathJax@2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<title>state-space-search</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>

<div id="State space search"><h1 id="State space search">State space search</h1></div>
<p>
How do we find the solutions of previous problems?
</p>
<ul>
<li>
search the state space

<li>
search through explicit tree generation: root is initial state, nodes/leaves generated through successor function

<li>
search generates a graph

</ul>

<p>
state: representation of a physical configuration
</p>

<p>
node: data structure in the search tree. it contains state, parent node, actions, etc.
</p>

<div id="State space search-Uninformed search strategies"><h2 id="Uninformed search strategies">Uninformed search strategies</h2></div>
<p>
strategy defines picking order of node expansion
</p>

<p>
uninformed methods: only use problem definition
</p>

<p>
informed methods: use heuristic function to estimate cost of solution
</p>

<p>
evaluating performance:
</p>
<ul>
<li>
does it always find a solution if there is one? (completeness)

<li>
does it find least-cost solution? (optimality)

<li>
how many nodes generated/expanded? (time complexity)

<li>
how many nodes are stored in memory during search? (space complexity)

<li>
complexity measured in terms of:

<ul>
<li>
b: max branching factor of search tree)

<li>
d: depth of least cost solution

<li>
m: max depth of state space, could be infinite

</ul>
<li>
time/space complexity measured in terms of max branching factor of search tree, depth of least cost solution, max depth of state space (could be infinite)

</ul>

<p>
<img src="img/search-alg-summary.png" alt="Summary of uninformed search algorithms" />
</p>

<div id="State space search-Uninformed search strategies-Breadth-first (BF) search"><h3 id="Breadth-first (BF) search">Breadth-first (BF) search</h3></div>
<ul>
<li>
algorithm:

<ul>
<li>
expand shallowest unexpanded node

<li>
implementation - fringe (nodes that have to be explored) is a FIFO queue

</ul>
<li>
evaluation:

<ul>
<li>
completeness: yes, if branching factor b is finite

<li>
time complexity: if every state has b successors, and solution is at depth d, then \(O(b^{d+1})\) because of number of nodes generated

<li>
space complexity: shitty if every node has to be in memory - \(O(b^{d+1})\)

<li>
optimality: in general yes, unless actions have different cost

</ul>
<li>
memory requirements are bigger problem than execution time

</ul>

<div id="State space search-Uninformed search strategies-Depth-first (DF) search"><h3 id="Depth-first (DF) search">Depth-first (DF) search</h3></div>
<ul>
<li>
algorithm:

<ul>
<li>
expand deepest unexpanded node

<li>
implementation: fringe is a stack

</ul>
<li>
evaluation:

<ul>
<li>
completeness: no, unless search space is finite and no loops are possible

<li>
time complexity: shitty if m is larger than d (depth of optimal solution) -- \(O(b^m)\). but if many solutions, faster than BF

<li>
space complexity: backtracking search uses less memory, one successor instead of all b -- \(O(bm+1)\)

<li>
optimality: no, same issues as completeness

</ul>
</ul>

<div id="State space search-Uninformed search strategies-Depth-limited search"><h3 id="Depth-limited search">Depth-limited search</h3></div>
<ul>
<li>
DF-search with depth limit l (nodes at depth l have no successors)

<li>
solves infinite-path problem

<li>
evaluation:

<ul>
<li>
time: \(O(b^l)\)

<li>
space: \(O(bl)\)

<li>
completeness: not if l &lt; d

<li>
optimality: not if if l &gt; d

</ul>
</ul>

<div id="State space search-Uninformed search strategies-Iterative deepening search"><h3 id="Iterative deepening search">Iterative deepening search</h3></div>
<ul>
<li>
strategy to find best depth limit l

<li>
often used in combination with DF search

<li>
after each iteration, throw away everything and increase depth limit

<li>
combines benefits of DF (space complexity) and BF search (time complexity)

<li>
evaluation:

<ul>
<li>
completeness: yes (no infinite paths)

<li>
time: \(O(b^d)\)

<li>
space: \(O(bd)\)

</ul>
</ul>

<div id="State space search-Informed search (heuristics)"><h2 id="Informed search (heuristics)">Informed search (heuristics)</h2></div>

<p>
Heuristic function: "educated guess that reduces/limits search for solutions"
</p>

<p>
informedness property of heuristics:
</p>
<ul>
<li>
two heuristics \(h_1(n),\; h_2(n)\) with \(0 \leq h_1(n) \leq h_2(n) \leq h*(n)\)

<li>
then \(h_2(n)\) is more informed than \(h_1(n)\)

<li>
with \(h_1\) fewer nodes have to be searched with \(h_2\)

<li>
but \(h_2\) is often more expensive to calculate

<li>
perfect heuristics: \(h(n) = h*(n)\)

<li>
trivial heuristics: \(h(n) = 0\)

</ul>

<p>
Best-first search
</p>
<ul>
<li>
the general approach of informed search

<li>
node selected for expansion based on <em>evaluation function f(n)</em>

<li>
evaluation function measures distance to goal, choose node which appears best

<li>
fringe is queue in order of decreasing desirability

</ul>

<div id="State space search-Informed search (heuristics)-A Search"><h3 id="A Search">A Search</h3></div>
<p>
best-known form of best-first search
</p>

<p>
avoid expanding paths that are already expensive
</p>

<p>
evaluation function: \(f(n) = g(n) + h(n)\)
</p>
<ul>
<li>
g(n) the cost so far to reach node n

<li>
h(n) estimated cost to get from node n to goal

<li>
f(n) estimated total cost of path through node n to goal

</ul>

<div id="State space search-Informed search (heuristics)-A* Search"><h3 id="A* Search">A* Search</h3></div>

<p>
A search, but with an admissible heuristic
</p>
<ul>
<li>
heuristic is admissible if it <em>never</em> overestimates the cost to get to goal

<li>
admissible heuristics are optimistic

<li>
formally: \(h(n) \leq h*(n)\) where \(h*(n)\) is true cost from n to goal

</ul>

<p>
evaluation:
</p>
<ul>
<li>
complete: yes

<li>
time: exponential with path length

<li>
space: all nodes are stored

<li>
optimal: yes

</ul>

<div id="State space search-Adversarial search"><h2 id="Adversarial search">Adversarial search</h2></div>
<p>
search has no adversary, solution is a (heuristic) method for finding a goal
</p>

<p>
games have an adversary, solution is a strategy. time limits force an <em>approximate</em> solution.
</p>

<p>
you need a function to evaluate the "goodness" of a game position
</p>

<p>
types of games:
</p>

<table>
<tr>
<th>
&nbsp;
</th>
<th>
deterministic
</th>
<th>
chance
</th>
</tr>
<tr>
<td>
perfect information
</td>
<td>
chess, checkers, go, othello
</td>
<td>
backgammon, monopoly
</td>
</tr>
<tr>
<td>
imperfect information
</td>
<td>
&nbsp;
</td>
<td>
bridge poker, scrabble, nuclear war
</td>
</tr>
</table>

<div id="State space search-Adversarial search-Minimax"><h3 id="Minimax">Minimax</h3></div>

<div id="State space search-Adversarial search-Minimax-Setup"><h4 id="Setup">Setup</h4></div>
<p>
two players: MAX, MIN
</p>

<p>
MAX moves first, take turns until game is over. winner gets award, loser gets penalty.
</p>

<p>
how does this relate to search?
</p>
<ul>
<li>
initial state: game configuration e.g. with chess

<li>
successor function: list of &lt;move, state&gt; pairs with legal moves

<li>
terminal test: game finished?

<li>
utility function: numerical value of terminal states (win +1, lose -1, draw 0)

<li>
MAX uses search tree to determine next move

</ul>

<div id="State space search-Adversarial search-Minimax-Optimal strategies"><h4 id="Optimal strategies">Optimal strategies</h4></div>

<p>
find contingent strategy for MAX assuming infallible MIN.
</p>

<p>
assume that both players play optimally.
</p>

<p>
given game tree, optimal strategy can be found with minimax value of each node:
</p>

<pre>
    minimax(n) = utility(n)                      if n is a terminal
                 minimax(max(successors of n))   if n is a max node
                 minimax(min(successors of n))   if n is a min node
</pre>

<div id="State space search-Adversarial search-Minimax-Evaluation"><h4 id="Evaluation">Evaluation</h4></div>
<ul>
<li>
complete: yes

<li>
time: \(O(b^m)\)

<li>
space: \(O(bm)\)

<li>
optimal: yes

</ul>

<div id="State space search-Adversarial search-Reducing problems of complexity with Minimax"><h3 id="Reducing problems of complexity with Minimax">Reducing problems of complexity with Minimax</h3></div>

<div id="State space search-Adversarial search-Reducing problems of complexity with Minimax-Cutting off search:"><h4 id="Cutting off search:">Cutting off search:</h4></div>
<p>
instead of <code>if TERMINAL(state) then return UTILITY(state)</code> do <code>if CUTOFF-TEST(state, depth) then return EVAL(state)</code>
</p>

<p>
this introduces fixed-limit depth. also loses completeness!
</p>

<p>
utility: value based on quality of state
</p>

<p>
heuristics: value based on estimation of quality of state
</p>

<p>
heuristic EVAL:
</p>
<ul>
<li>
produces estimate of expected utility of a game from a given position

<li>
should order terminal nodes in same way as utility

<li>
computation shouldn't take too long

</ul>

<div id="State space search-Adversarial search-Reducing problems of complexity with Minimax-Alpha-Beta pruning (efficient Minimax)"><h4 id="Alpha-Beta pruning (efficient Minimax)">Alpha-Beta pruning (efficient Minimax)</h4></div>

<p>
with minimax, the number of states is exponential to number of moves
</p>

<p>
so, don't examine every node and prune the subtrees you don't have to examine
</p>

<p>
Alpha: value of best MAX choice so far
</p>

<p>
Beta: value of best MIN choice so far
</p>

<p>
you prune the rest of the level if, at any point, beta &lt;= alpha.
</p>

<p>
pruning doesn't affect final results, entire subtrees can be pruned
</p>

<p>
good move ordering improves effectiveness of pruning
</p>

<p>
with 'perfect ordering', time complexity is: \(O(b^{m/2})\)
</p>

<div id="State space search-Adversarial search-Search with no or partial information"><h3 id="Search with no or partial information">Search with no or partial information</h3></div>

<p>
problems:
</p>
<ul>
<li>
contingency: percepts provide new info

<li>
exploration: when states/actions of environment are unknown

<li>
sensorless/conformant: agent may have no idea where it is

</ul>

<div id="State space search-Adversarial search-Search with no or partial information-Perfect information Monte Carlo sampling (rdeep)"><h4 id="Perfect information Monte Carlo sampling (rdeep)">Perfect information Monte Carlo sampling (rdeep)</h4></div>
<ol>
<li>
rollout:

<ul>
<li>
assume a belief state (with perfect info)

<li>
play random game in that state.

</ul>
<li>
average the rollouts

<li>
choose one with max average

</ol>

<div id="State space search-Adversarial search-Games with chance"><h3 id="Games with chance">Games with chance</h3></div>
<p>
<img src="img/games-chance.png" alt="Games with chance" />
</p>

<div id="State space search-Summary (Schnapsen)"><h2 id="Summary (Schnapsen)">Summary (Schnapsen)</h2></div>
<p>
Phase 2: minimax &amp; alpha-beta pruning
</p>

<p>
Phase 1: PIMC sampling
</p>

<p>
what next? give the agent information about the game
</p>

<div id="State space search-Search direction"><h2 id="Search direction">Search direction</h2></div>
<p>
Data-driven: start with initial state (e.g. a maze)
</p>

<p>
Goal-driven: start with goal state, but has bigger branching factor (<span class="todo">TODO</span> confirm this)
</p>

</body>
</html>
