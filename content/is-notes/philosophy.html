<!DOCTYPE html>
<html>
<head>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/gh/mathjax/MathJax@2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<link rel="Stylesheet" type="text/css" href="style.css">
<title>philosophy</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>

<div id="Philosophy of AI"><h1 id="Philosophy of AI">Philosophy of AI</h1></div>
<p>
what is intelligence?
</p>
<ul>
<li>
classically, you test this using the Turing Test

<ul>
<li>
interrogation game

<li>
interrogate two parties, the goal of both parties is to convince the interrogator that they are human

<li>
if the interrogator can't tell who is the human, the computer is intelligent

</ul>
<li>
the objections:

<ul>
<li>
the test is subjective

<li>
why are we basing intelligence on <em>human</em> intelligence? metaphor with flight, we only managed to get off the ground once we stopped imitating natural flight 

</ul>
</ul>

<p>
intelligence is everything a computer can't do yet.
</p>

<p>
can a computer be intelligent?
</p>
<ul>
<li>
substitution argument: if you replace one neuron at a time with a computer chip in the human brain, you would eventually change into a computer, without your conscience or thought process changing at any point.

<li>
medium argument: no. "carbohydrate racism", there's something special about carbohydrates that allows us to do stuff that computers can't do.

<li>
formal systems argument: no. mathematical systems are inherently limited in some way; since computers are just formal systems, therefore they inherently have some limitations. we are not formal systems (that's debatable) so we do not have those limitations.

<li>
symbol-grounding: learning systems manipulate symbols

<ul>
<li>
symbols can only refer to other symbols, so how can a computer ever know what's "red", "heavy", "sad" in the 'real' world?

<li>
so simulated intelligence â‰  real intelligence

<li>
thought experiment - the Chinese Room:

<ul>
<li>
a room with Chinese symbols coming in

<li>
there's one person inside that uses a book to translate Chinese symbols to other symbols

<li>
there's nothing in this system that understands Chinese

</ul>
</ul>
</ul>

<p>
Mind-body problem:
</p>
<ul>
<li>
we have the physical body, and metaphysical thoughts

<li>
what could be the relationship between the physical and the metaphysical? 

<li>
opinions:

<ul>
<li>
mind-body dualism, interactionism: we consist of two parts (physical <em>and</em> metaphysical) --  Descartes 

<li>
materialism: the mind and body is one thing

<li>
gradualism: we evolved the mind (intelligence, consciousness) over time

</ul>
</ul>

<p>
Intentional stance:
</p>
<ul>
<li>
intelligence/consciousness is "attributed" and "gradual"

<li>
so the question isn't "will computers ever be conscious?", but rather "will we ever use consciousness-related words to describe them?"

<li>
if it's useful to talk about consciousness, motivation, feeling, etc., then we are allowed to (or should) do so equally for both humans and machines

<li>
people have a strong tendency to take the intentional stance, so we will <em>call</em> our computers "intelligent"

</ul>

<p>
Free will:
</p>
<ul>
<li>
reasons why it can't be true:

<ul>
<li>
physics is deterministic, you can predict the next states, so your brain doesn't <em>physically</em> allow free will

<li>
inconsistent with psychology and neuroscience -- motor areas begin activity 2 seconds before we think we want to do something (<a href="https://www.youtube.com/watch?v=IQ4nwTTmcgs">Libet's experiment</a>)

</ul>
</ul>

</body>
</html>
