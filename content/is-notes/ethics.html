<!DOCTYPE html>
<html>
<head>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/gh/mathjax/MathJax@2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<link rel="Stylesheet" type="text/css" href="style.css">
<title>ethics</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>

<div id="Ethics of AI"><h1 id="Ethics of AI">Ethics of AI</h1></div>
<p>
three main questions:
</p>
<ul>
<li>
how do we encode ethical behavior?

<li>
how should we behave towards AI?

<li>
how does the existence of AI affects our daily lives?

</ul>
<blockquote>
"Ethics begins when elements of a moral system conflict."
</blockquote>

<p>
Fundamental ethics: moral absolutism, you are not allowed to do something due to e.g. religion
</p>

<p>
Pragmatic ethics: humans always have a choice, you have the freedom of choice at any point in time
</p>

<div id="Ethics of AI-Sci-fi ethics (problems down the road)"><h2 id="Sci-fi ethics (problems down the road)">Sci-fi ethics (problems down the road)</h2></div>
<p>
Asimov's laws:
</p>
<ol>
<li>
A robot may not injure a human being or, through inaction, allow a human being to come to harm.

<li>
A robot must obey the orders given to it by human beings except where such orders would conflict with the First Law. 

<li>
A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.

</ol>

<p>
The trolley problem is a good example of an ethical dilemma, and can be extended to self-driving cars (should it kill the driver or bystanders?).
</p>

<p>
How do we treat AI? How should we?
</p>

<div id="Ethics of AI-Today's problems"><h2 id="Today's problems">Today's problems</h2></div>
<ul>
<li>
Autonomous weapons: weapons that decide what to do by themselves

<ul>
<li>
what are we allowing these systems to do?

<li>
the Dutch government said it's fine "if there's a human in the wider loop"...but this is very vague, what is the wider loop?

</ul>
<li>
Privacy

<ul>
<li>
big companies have a bunch of data about people

<li>
often, people give this data for free.

</ul>
<li>
Profiling (e.g. racial)

<ul>
<li>
e.g. a black person was stopped while driving in an expensive car because the system thought he could only be driving the car if he stole it.

</ul>
</ul>

<p>
Prosecutor's fallacy:
</p>
<ul>
<li>
using probabilities incorrectly. \(P(\text{black} | \text{uses drugs}) \neq P(\text{uses drugs} | \text{black})\)

</ul>

</body>
</html>
